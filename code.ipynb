{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preamble: <br>\n",
    "Author: Stephen Brownsey  <br>\n",
    "Python version: 3.10.5 64-bit  <br>\n",
    "\n",
    "\n",
    "The problem is to predict which cases will lapse and is broken down into three sections:\n",
    "1. Data exploration: What are the most interesting features of the data set? What have you considered and why have you made the decisions you have done?\n",
    "2. Modelling: What process did you follow when modelling retention? How have you designed your model and what did you account for\n",
    "3. What are your conclusions and what else would’ve been useful to know?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\steph\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Library loading section\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn as skl\n",
    "import sweetviz as sv\n",
    "from tqdm import tqdm\n",
    "from utils import get_missing_column_values\n",
    "from datetime import datetime, date\n",
    "from dateutil.relativedelta import relativedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/home_insurance.csv\").drop(columns = [\"i\", \"Police\"], errors = \"ignore\") #Dropping the two identifier columns i is the index and police is the police number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Categorical Features:  41\n",
      "Number of Numeric Features: 23\n"
     ]
    }
   ],
   "source": [
    "#First look\n",
    "print(\"Number of Categorical Features: \", len([x for x in data.select_dtypes(include=['object'])]))\n",
    "print(\"Number of Numeric Features:\", len([x for x in data.select_dtypes(exclude=['object'])]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sweetviz is a very good EDA library that shows you information about all the columns in the dataframe, takes a few minutes to run, so just open raw_data.html from repo to see this output\n",
    "#my_report = sv.analyze(data, target_feat = \"POL_STATUS\")\n",
    "#my_report.show_html(\"raw_data.html\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sweetviz report quickly tells us a few things about the dataset:\n",
    "1. There are 67115 cases where there is a missing policy status, since this is our dependent variable, rows which are missing here should be removed. This number of 67115 is also present in a lot of the other variables as such it backs up this thought. There are also 16 Unknown policies, since this is such a low number we can afford to remove them as well\n",
    "2. There are some irrelevant columns which only have one option such as PAYMENT_FREQUENCY and CAMPAIGN_DESC which is all missing.\n",
    "3. There are a number of variables that are majority missing, more analysis will be undertaken for these but it is expected that most will be dropped before modelling.\n",
    "4. There are a number of date variables, which should be put through feature engineering before we add them to our model\n",
    "5. Some columns are very heavily skewed so to consider whether these should be considered for the model or not\n",
    "6. There are some numerical columns such as SUM_INSURED_CONTENTS/SUM_INSURED_BUILDING that are more ordinal than continuous so should be encoded as such\n",
    "7. There are very strong associations between a lot of the columns, particularly around pre renewal and post renewal columns which highlights perhaps they should be combined. As well as sum assured and premium columns which are very strongly linked. The dataset should go through a rigourous feature selection process before being used for modelling to iron out as much of these correlations as possible\n",
    "8. There are some outliers which will need looking at in more detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RISK_RATED_AREA_B</th>\n",
       "      <th>SUM_INSURED_BUILDINGS</th>\n",
       "      <th>NCD_GRANTED_YEARS_B</th>\n",
       "      <th>RISK_RATED_AREA_C</th>\n",
       "      <th>SUM_INSURED_CONTENTS</th>\n",
       "      <th>NCD_GRANTED_YEARS_C</th>\n",
       "      <th>SPEC_SUM_INSURED</th>\n",
       "      <th>SPEC_ITEM_PREM</th>\n",
       "      <th>UNSPEC_HRP_PREM</th>\n",
       "      <th>BEDROOMS</th>\n",
       "      <th>...</th>\n",
       "      <th>MAX_DAYS_UNOCC</th>\n",
       "      <th>OWNERSHIP_TYPE</th>\n",
       "      <th>PAYING_GUESTS</th>\n",
       "      <th>PROP_TYPE</th>\n",
       "      <th>YEARBUILT</th>\n",
       "      <th>CAMPAIGN_DESC</th>\n",
       "      <th>PAYMENT_FREQUENCY</th>\n",
       "      <th>MTA_FAP</th>\n",
       "      <th>MTA_APRP</th>\n",
       "      <th>LAST_ANN_PREM_GROSS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>340.000000</td>\n",
       "      <td>1018.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>223.310382</td>\n",
       "      <td>96.815647</td>\n",
       "      <td>208.483094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>109.129222</td>\n",
       "      <td>135.085932</td>\n",
       "      <td>101.016586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.910000</td>\n",
       "      <td>-78.590000</td>\n",
       "      <td>-1.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>152.257500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>141.207500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>198.575000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>187.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>278.680000</td>\n",
       "      <td>194.570000</td>\n",
       "      <td>260.105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>650.380000</td>\n",
       "      <td>600.820000</td>\n",
       "      <td>721.960000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       RISK_RATED_AREA_B  SUM_INSURED_BUILDINGS  NCD_GRANTED_YEARS_B  \\\n",
       "count                0.0                    0.0                  0.0   \n",
       "mean                 NaN                    NaN                  NaN   \n",
       "std                  NaN                    NaN                  NaN   \n",
       "min                  NaN                    NaN                  NaN   \n",
       "25%                  NaN                    NaN                  NaN   \n",
       "50%                  NaN                    NaN                  NaN   \n",
       "75%                  NaN                    NaN                  NaN   \n",
       "max                  NaN                    NaN                  NaN   \n",
       "\n",
       "       RISK_RATED_AREA_C  SUM_INSURED_CONTENTS  NCD_GRANTED_YEARS_C  \\\n",
       "count                0.0                   0.0                  0.0   \n",
       "mean                 NaN                   NaN                  NaN   \n",
       "std                  NaN                   NaN                  NaN   \n",
       "min                  NaN                   NaN                  NaN   \n",
       "25%                  NaN                   NaN                  NaN   \n",
       "50%                  NaN                   NaN                  NaN   \n",
       "75%                  NaN                   NaN                  NaN   \n",
       "max                  NaN                   NaN                  NaN   \n",
       "\n",
       "       SPEC_SUM_INSURED  SPEC_ITEM_PREM  UNSPEC_HRP_PREM  BEDROOMS  ...  \\\n",
       "count               0.0             0.0              0.0       0.0  ...   \n",
       "mean                NaN             NaN              NaN       NaN  ...   \n",
       "std                 NaN             NaN              NaN       NaN  ...   \n",
       "min                 NaN             NaN              NaN       NaN  ...   \n",
       "25%                 NaN             NaN              NaN       NaN  ...   \n",
       "50%                 NaN             NaN              NaN       NaN  ...   \n",
       "75%                 NaN             NaN              NaN       NaN  ...   \n",
       "max                 NaN             NaN              NaN       NaN  ...   \n",
       "\n",
       "       MAX_DAYS_UNOCC  OWNERSHIP_TYPE  PAYING_GUESTS  PROP_TYPE  YEARBUILT  \\\n",
       "count             0.0             0.0            0.0        0.0        0.0   \n",
       "mean              NaN             NaN            NaN        NaN        NaN   \n",
       "std               NaN             NaN            NaN        NaN        NaN   \n",
       "min               NaN             NaN            NaN        NaN        NaN   \n",
       "25%               NaN             NaN            NaN        NaN        NaN   \n",
       "50%               NaN             NaN            NaN        NaN        NaN   \n",
       "75%               NaN             NaN            NaN        NaN        NaN   \n",
       "max               NaN             NaN            NaN        NaN        NaN   \n",
       "\n",
       "       CAMPAIGN_DESC  PAYMENT_FREQUENCY     MTA_FAP    MTA_APRP  \\\n",
       "count            0.0                0.0  340.000000  340.000000   \n",
       "mean             NaN                NaN  223.310382   96.815647   \n",
       "std              NaN                NaN  109.129222  135.085932   \n",
       "min              NaN                NaN   -1.910000  -78.590000   \n",
       "25%              NaN                NaN  152.257500    0.000000   \n",
       "50%              NaN                NaN  198.575000    0.000000   \n",
       "75%              NaN                NaN  278.680000  194.570000   \n",
       "max              NaN                NaN  650.380000  600.820000   \n",
       "\n",
       "       LAST_ANN_PREM_GROSS  \n",
       "count          1018.000000  \n",
       "mean            208.483094  \n",
       "std             101.016586  \n",
       "min              -1.910000  \n",
       "25%             141.207500  \n",
       "50%             187.760000  \n",
       "75%             260.105000  \n",
       "max             721.960000  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking into point 1:\n",
    "# Quick look into the Null Policy status rows to see if it contains anything useful\n",
    "data[pd.isnull(data.POL_STATUS)].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now update the data view to remove Unknown and Null policies\n",
    "data = data[ (~pd.isnull(data.POL_STATUS)) & (data.POL_STATUS != \"Unknown\")]\n",
    "#my_report = sv.analyze(data, target_feat = \"POL_STATUS\")\n",
    "#my_report.show_html(\"full_dataset.html\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Point 2/Point 3: <br>\n",
    "From point 2 it can be seen that PAYMENT_FREQUENCY AND CAMPAIGN_DESC should be dropped from the analysis as they are irrelevant.\n",
    "Looking into Point 3, to start with will drop P1_PT_EMP_STATUS and CLERICAL as very high percentage missing and \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing_percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P1_PT_EMP_STATUS</td>\n",
       "      <td>187223</td>\n",
       "      <td>99.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CLERICAL</td>\n",
       "      <td>186061</td>\n",
       "      <td>98.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MTA_DATE</td>\n",
       "      <td>162578</td>\n",
       "      <td>86.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MTA_FAP</td>\n",
       "      <td>133630</td>\n",
       "      <td>70.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MTA_APRP</td>\n",
       "      <td>133630</td>\n",
       "      <td>70.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QUOTE_DATE</td>\n",
       "      <td>109868</td>\n",
       "      <td>58.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RISK_RATED_AREA_B</td>\n",
       "      <td>48140</td>\n",
       "      <td>25.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RISK_RATED_AREA_C</td>\n",
       "      <td>8731</td>\n",
       "      <td>4.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              column  missing_count  missing_percentage\n",
       "1   P1_PT_EMP_STATUS         187223               99.06\n",
       "2           CLERICAL         186061               98.44\n",
       "7           MTA_DATE         162578               86.02\n",
       "5            MTA_FAP         133630               70.70\n",
       "6           MTA_APRP         133630               70.70\n",
       "0         QUOTE_DATE         109868               58.13\n",
       "3  RISK_RATED_AREA_B          48140               25.47\n",
       "4  RISK_RATED_AREA_C           8731                4.62"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at point 2:\n",
    "data.drop([\"PAYMENT_FREQUENCY\", \"CAMPAIGN_DESC\"],axis = 1, inplace=True)\n",
    "missing_info = get_missing_column_values(df = data)\n",
    "missing_info\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_insight(column, data = data):\n",
    "    nulled = data[(pd.isnull(data[column]))][\"POL_STATUS\"]\n",
    "    contained = data[ (~pd.isnull(data[column]))][\"POL_STATUS\"] \n",
    "    total_null = len(nulled)\n",
    "    total_contained = len(contained)\n",
    "    nulled = pd.DataFrame(nulled.value_counts() ).rename(columns= {\"POL_STATUS\": \"nulled\"})\n",
    "    contained = pd.DataFrame(contained.value_counts()).rename(columns= {\"POL_STATUS\": \"contained\"})\n",
    "    df = pd.concat([nulled, contained], axis = 1).reset_index().rename(columns = {\"index\":\"POL_STATUS\"})\n",
    "    df[\"index\"] = round( (df.contained/total_contained)/(df.nulled/total_null), 3)\n",
    "    df[\"column\"] = column\n",
    "    return df[[\"column\", \"POL_STATUS\", \"contained\", \"nulled\", \"index\"]]\n",
    "\n",
    "indexes = index_insight('P1_PT_EMP_STATUS')\n",
    "iterate_cols = missing_info.column.unique().tolist()\n",
    "iterate_cols.remove('P1_PT_EMP_STATUS')\n",
    "\n",
    "for column in iterate_cols:\n",
    "    temp = index_insight(column)\n",
    "    indexes = pd.concat([indexes, temp])\n",
    "indexes\n",
    "    \n",
    "data.drop([\"P1_PT_EMP_STATUS\", \"CLERICAL\"], axis = 1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at NAs in MTA_FAP and MTA_APRP: These columns are the bonusup to date of adjustment and the adjustment of the premium\n",
    "# going to replace all the NaNs with 0 as if there was no adjustment then no midterm change occured\n",
    "data[[\"MTA_FAP\", \"MTA_APRP\"]] = data[[\"MTA_FAP\", \"MTA_APRP\"]].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the RISK_Rated columns, we note that a higher number can be associated with a higher risk\n",
    "# 0 is the most common result for both of them and it would be a reasonable assumption that if it was null then there is a low risk so again just going to fillnas with 0\n",
    "# Potentially could build another model to predict the number , but feels overkill\n",
    "data[[\"RISK_RATED_AREA_B\", \"RISK_RATED_AREA_C\"]] = data[[\"RISK_RATED_AREA_B\", \"RISK_RATED_AREA_C\"]].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Point 4: <br>\n",
    "There are 4 columns which are dates - these are encoded as object columns in the df, so convert them to datetime and perform feature engineering on them.\n",
    "Columns are: QUOTE_DATE, COVER_START, P1_DOB, MTA_DATE <br>\n",
    "Feature engineering of date columns:<br>\n",
    "MTA_DATE will be dropped, this is due both the large % of missing data and the three other MTA related columns <br>\n",
    "P1_DOB will be changed to age at policy start <br>\n",
    "For COVER_START day and month will be extracted as could provide some insight if there are weekly/day variations <br>\n",
    "QUOTE_DATE has lots of nulls, so we'll change it to a categorical column of \"Unknown\", \"Same as Cover Start\", \"within 2 week of cover start\" and \"great than 2 weeks of cover start\". There could be an underlying reason for the Nulls such as that policy came in via an agent so was always on the same day as start date, but without deeper knowledge of the dataset impossible for know so just encoding to \"Unknown\" for now. There were some cases that QUOTE_DATE is after COVER_START which looks wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"QUOTE_DATE\", \"COVER_START\", \"P1_DOB\", \"MTA_DATE\"]] = data[[\"QUOTE_DATE\", \"COVER_START\", \"P1_DOB\", \"MTA_DATE\"]].apply(lambda _: pd.to_datetime(_, infer_datetime_format=True ,errors='coerce'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Cases with Quote Date After Start Date: 475\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data[\"quote_variation\"] = (data.COVER_START - data.QUOTE_DATE)/np.timedelta64(1, \"D\")\n",
    "print(\"Number of Cases with Quote Date After Start Date: \" + str(len(data[\"quote_variation\"][data.quote_variation < 0])))\n",
    "\n",
    "def quote_date_updator(row):\n",
    "    if(pd.isnull(row)):\n",
    "        return \"unknown\"\n",
    "    elif(abs(row) <= 14):\n",
    "        return \"less_than_14_days\"\n",
    "    elif(abs(row) > 14):\n",
    "        return \"greater_than_14_days\"\n",
    "\n",
    "\n",
    "data[\"quote_variation\"] = data.quote_variation.apply(quote_date_updator)#.value_counts()\n",
    "data.drop(\"QUOTE_DATE\", axis = 1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating user age\n",
    "data['Age'] = (data['COVER_START'] - data['P1_DOB']).astype('timedelta64[Y]').astype('int')\n",
    "data.drop(\"P1_DOB\", axis = 1, inplace=True)\n",
    "#Switching Quote and Cover Start days into Day of week and month of year\n",
    "def date_feature_engineerer(data = data, column = \"COVER_START\", prefix = \"cover_start\"):\n",
    "    column1 = prefix + \"_day_of_week\"\n",
    "    column2 = prefix + \"_month\"\n",
    "    data[column1] = data[column].dt.day_name()\n",
    "    data[column2] = data[column].dt.month_name()\n",
    "    data.drop(column, axis = 1, inplace=True)\n",
    "\n",
    "date_feature_engineerer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Point 5:\n",
    "\n",
    "Going to use an XGB algorithm to start with and this handles skewed data well so no need to overly worry about it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Point 6:\n",
    "Encoding the ordinal float columns instead of continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_sum_insured_contents(row):\n",
    "    if row == 0:\n",
    "        return 0\n",
    "    elif row == 50000:\n",
    "        return 1\n",
    "    elif row == 55000:\n",
    "        return 2\n",
    "    elif row == 60000:\n",
    "        return 3\n",
    "    elif row == 65000:\n",
    "        return 4\n",
    "    elif row == 70000:\n",
    "        return 5\n",
    "    elif row == 75000:\n",
    "        return 6\n",
    "    elif row == 80000:\n",
    "        return 7\n",
    "    elif row == 85000:\n",
    "        return 8\n",
    "    elif row == 90000:\n",
    "        return 9\n",
    "    else:\n",
    "        return 10\n",
    "\n",
    "data[\"SUM_INSURED_CONTENTS\"] = data[\"SUM_INSURED_CONTENTS\"].apply(update_sum_insured_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"SUM_INSURED_BUILDINGS\"] = data[\"SUM_INSURED_BUILDINGS\"].replace({0.0:\"N\", 1000000.0:\"Y\"})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Points 7\n",
    "Looking at the strong associations in the data, going to combine the pre and post columns into one column <br>\n",
    "Going to remove the premium columns, these are driving by a combination of the other columns, particularly sum assured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_post_combiner(data = data, column = \"LEGAL_ADDON\"):\n",
    "    \"\"\"Combine pre and post columns\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame, optional): Dataframe to apply combining to. Defaults to data.\n",
    "        column (str, optional): Column to apply combining to. Defaults to \"LEGAL_ADDON\".\n",
    "    \"\"\"\n",
    "    pre = column + \"_ADDON_PRE_REN\"\n",
    "    post = column + \"_ADDON_POST_REN\"\n",
    "    data[column] = data[pre] + data[post]\n",
    "    data.drop([pre, post], axis = 1, inplace=True)\n",
    "\n",
    "cols = [\"LEGAL\", \"HOME_EM\", \"GARDEN\", \"KEYCARE\", \"HP1\", \"HP2\", \"HP3\"]\n",
    "for col in cols:\n",
    "    pre_post_combiner(column = col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the Premium columns - signified by _PREM_ so it keeps last years premium\n",
    "data.drop(list(data.filter(regex = '_PREM_')), axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RISK_RATED_AREA_B</th>\n",
       "      <th>NCD_GRANTED_YEARS_B</th>\n",
       "      <th>RISK_RATED_AREA_C</th>\n",
       "      <th>SUM_INSURED_CONTENTS</th>\n",
       "      <th>NCD_GRANTED_YEARS_C</th>\n",
       "      <th>SPEC_SUM_INSURED</th>\n",
       "      <th>SPEC_ITEM_PREM</th>\n",
       "      <th>UNSPEC_HRP_PREM</th>\n",
       "      <th>BEDROOMS</th>\n",
       "      <th>ROOF_CONSTRUCTION</th>\n",
       "      <th>...</th>\n",
       "      <th>HP1_YN</th>\n",
       "      <th>HP1_YY</th>\n",
       "      <th>HP2_NN</th>\n",
       "      <th>HP2_NY</th>\n",
       "      <th>HP2_YN</th>\n",
       "      <th>HP2_YY</th>\n",
       "      <th>HP3_NN</th>\n",
       "      <th>HP3_NY</th>\n",
       "      <th>HP3_YN</th>\n",
       "      <th>HP3_YY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7500.0</td>\n",
       "      <td>44.42</td>\n",
       "      <td>12.45</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24.60</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>19.82</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 137 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RISK_RATED_AREA_B  NCD_GRANTED_YEARS_B  RISK_RATED_AREA_C  \\\n",
       "0               19.0                  7.0                6.0   \n",
       "1               25.0                  6.0                9.0   \n",
       "2                0.0                  0.0               12.0   \n",
       "3                0.0                  0.0               14.0   \n",
       "4                5.0                  7.0               10.0   \n",
       "\n",
       "   SUM_INSURED_CONTENTS  NCD_GRANTED_YEARS_C  SPEC_SUM_INSURED  \\\n",
       "0                     1                  7.0            7500.0   \n",
       "1                     1                  7.0               0.0   \n",
       "2                     1                  7.0               0.0   \n",
       "3                     1                  7.0               0.0   \n",
       "4                     1                  7.0               0.0   \n",
       "\n",
       "   SPEC_ITEM_PREM  UNSPEC_HRP_PREM  BEDROOMS  ROOF_CONSTRUCTION  ...  HP1_YN  \\\n",
       "0           44.42            12.45       3.0               11.0  ...       0   \n",
       "1            0.00            24.60       3.0               11.0  ...       0   \n",
       "2            0.00             0.00       2.0               11.0  ...       0   \n",
       "3            0.00             0.00       2.0               11.0  ...       0   \n",
       "4            0.00            19.82       3.0               11.0  ...       0   \n",
       "\n",
       "   HP1_YY  HP2_NN  HP2_NY  HP2_YN  HP2_YY  HP3_NN  HP3_NY  HP3_YN HP3_YY  \n",
       "0       0       1       0       0       0       1       0       0      0  \n",
       "1       0       1       0       0       0       1       0       0      0  \n",
       "2       0       1       0       0       0       1       0       0      0  \n",
       "3       0       1       0       0       0       1       0       0      0  \n",
       "4       0       1       0       0       0       1       0       0      0  \n",
       "\n",
       "[5 rows x 137 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [x for x in data.select_dtypes(include=['object'])]\n",
    "modelling_df = pd.get_dummies(data, columns= cols)\n",
    "modelling_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7f3f82003cc0ccb780dfb68465a2859b8753c3cce133cefccb0357f6f67295b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
